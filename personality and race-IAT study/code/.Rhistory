# Create the exclusion variable
mutate(exclusion_trial = ifelse(trials_in_critical_blocks < 120, "exclude", "include")) %>%
ungroup()
# Join the exclusion data back to the main dataset
data_iat_dscores_with_exclusion <- data_iat_dscores %>%
left_join(data_iat_dscores_with_exclusion, by = "participant")
# View the dataset with exclusion variable
head(data_iat_dscores_with_exclusion)
# Create the performance exclusion variable
data_iat_new <- data_iat_dscores_with_exclusion %>%
filter(block %in% c(3, 4, 6, 7)) %>% # Filter to only include critical test blocks
mutate(
reaction_time = as.numeric(as.character(reaction_time)),
response = response == "correct" # Correctly convert accuracy to logical
) %>%
group_by(participant) %>%
summarise(
pct_fast_trials = mean(reaction_time < 300, na.rm = TRUE),
overall_accuracy = mean(response, na.rm = TRUE) # Use accuracy here
) %>%
mutate(
exclusion_performance = if_else(pct_fast_trials > 0.10 | overall_accuracy < 0.75, "exclude", "include")
) %>%
ungroup()
# Join the performance exclusion data back to the main dataset
data_iat_complete <- data_iat_dscores_with_exclusion %>%
left_join(data_iat_new, by = "participant")
# View the dataset with performance exclusion variable
head(data_iat_complete)
head(data_iat_new)
#First we rename unique_id in data_age_sex and, data_bfi_mean_scores to “participant” so that we can join them by participant
data_age_sex_rdy4merge <- data_age_sex %>%
rename(participant = unique_id)
data_bfi_mean_scores_ready4merge <- data_bfi_mean_scores %>%
rename(participant = unique_id)
library(tidyverse)
# Check the type of the participant column in each data frame
str(data_age_sex_rdy4merge$participant)
str(data_bfi_mean_scores_ready4merge$participant)
str(data_iat_complete$participant)
# If necessary, convert the participant column to character in all data frames
data_age_sex_rdy4merge$participant <- as.numeric(data_age_sex_rdy4merge$participant)
data_bfi_mean_scores_ready4merge$participant <- as.numeric(data_bfi_mean_scores_ready4merge$participant)
data_iat_complete$participant <- as.numeric(data_iat_complete$participant)
# join the datasets
data_merged_before_exclusions <- data_age_sex_rdy4merge %>%
full_join(data_bfi_mean_scores_ready4merge, by = "participant") %>%
full_join(data_iat_complete, by = "participant")
# create a master exclude_participant variable
data_processed <- data_merged_before_exclusions %>%
mutate(exclude_participant = case_when(is.na(age) ~ "exclude",
is.na(sex) ~ "exclude",
is.na(participant) ~"exclude",
is_likert == "exclude" ~ "exclude",
exclusion_trial == "exclude" ~ "exclude",
exclusion_performance == "exclude" ~ "exclude",
TRUE ~ "include"))
unique_participants_data <- data %>% distinct(participant, .keep_all = TRUE)
unique_participants_data <- data_processed %>% distinct(participant, .keep_all = TRUE)
View(unique_participants_data)
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
unique_participants_data <- data_processed %>% distinct(participant, .keep_all = TRUE)
#First we rename unique_id in data_age_sex and, data_bfi_mean_scores to “participant” so that we can join them by participant
data_age_sex_rdy4merge <- data_age_sex %>%
rename(participant = unique_id)
data_bfi_mean_scores_ready4merge <- data_bfi_mean_scores %>%
rename(participant = unique_id)
library(tidyverse)
# Check the type of the participant column in each data frame
str(data_age_sex_rdy4merge$participant)
str(data_bfi_mean_scores_ready4merge$participant)
str(data_iat_complete$participant)
# If necessary, convert the participant column to character in all data frames
data_age_sex_rdy4merge$participant <- as.numeric(data_age_sex_rdy4merge$participant)
data_bfi_mean_scores_ready4merge$participant <- as.numeric(data_bfi_mean_scores_ready4merge$participant)
data_iat_complete$participant <- as.numeric(data_iat_complete$participant)
# join the datasets
data_merged_before_exclusions <- data_age_sex_rdy4merge %>%
full_join(data_bfi_mean_scores_ready4merge, by = "participant") %>%
full_join(data_iat_complete, by = "participant")
unique_participants_data <- data_merged_before_exclusions %>% distinct(participant, .keep_all = TRUE)
# create a master exclude_participant variable
data_processed <- unique_participants_data %>%
mutate(exclude_participant = case_when(is.na(age) ~ "exclude",
is.na(sex) ~ "exclude",
is.na(participant) ~"exclude",
is_likert == "exclude" ~ "exclude",
exclusion_trial == "exclude" ~ "exclude",
exclusion_performance == "exclude" ~ "exclude",
TRUE ~ "include"))
getwd()
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
View(data_processed)
options(max.print=100)
View(data_processed)
View(data_processed_after_exclusion)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
group_by(sex) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(sex = stringr::str_to_sentence(sex)) |>
kable() |>
kable_classic(full_width = FALSE)
# Define the columns for each trait
traits <- list(
Agreeableness = c(“bfi_a1”, “bfi_a2", “bfi_a3”, “bfi_a4", “bfi_a5”, “bfi_a6", “bfi_a7”, “bfi_a8", “bfi_a9”),
# Define the columns for each trait
traits <- list(
Agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
Conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
Extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
Neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
Openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait to calculate alpha
for (trait in names(traits)) {
cat(trait, ": raw_alpha ", alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE)$total$raw_alpha, "is rated as good rel.\n")
}
# Define the columns for each trait
traits <- list(
Agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
Conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
Extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
Neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
Openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait to calculate alpha
for (trait in names(traits)) {
cat(trait, ": raw_alpha ", alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE)$total$raw_alpha, "is rated as good rel.\n")
}
# Define column sets for each personality trait
traits <- list(
agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait and calculate alpha
for (trait in names(traits)) {
cat("\n", trait, ": \n")
print(alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE))
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
group_by(sex) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(sex = stringr::str_to_sentence(sex)) |>
kable() |>
kable_classic(full_width = FALSE)
# Define column sets for each personality trait
traits <- list(
agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait and calculate alpha
for (trait in names(traits)) {
cat("\n", trait, ": \n")
print(alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE))
}
# Define column sets for each personality trait
traits <- list(
agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait and calculate alpha
for (trait in names(traits)) {
cat("\n", trait, ": \n")
print(alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE))
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
data_demographics <- read.csv("../data/raw/data_raw_demographics.csv") %>%
janitor::clean_names()
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv")
#getting rid of first row
data_iat_raw <- data_iat_raw[-1, ] %>%
janitor::clean_names()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
# Create a table with the total number of participants after exclusions.
data_processed_after_exclusions |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusions |>
group_by(sex) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(sex = stringr::str_to_sentence(sex)) |>
kable() |>
kable_classic(full_width = FALSE)
# Define column sets for each personality trait
traits <- list(
agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait and calculate alpha
for (trait in names(traits)) {
cat("\n", trait, ": \n")
print(alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE))
}
# Agreeableness: raw_alpha .79 is rated as good rel.
alpha(subset(data_processed_after_exclusions, select = c(bfi_a1, bfi_a2, bfi_a3, bfi_a4,
bfi_a5, bfi_a6, bfi_a7, bfi_a8,
bfi_a9)), check.keys = TRUE)
# Agreeableness: raw_alpha .79 is rated as good rel.
alpha(subset(data_processed_after_exclusions, select = c(bfi_a1, bfi_a2, bfi_a3, bfi_a4,
bfi_a5, bfi_a6, bfi_a7, bfi_a8,
bfi_a9)), check.keys = TRUE)
# Define the columns for each trait
traits <- list(
Agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
Conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
Extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
Neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
Openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait to calculate alpha
for (trait in names(traits)) {
cat(trait, ": raw_alpha ", alpha(subset(data_processed_after_exclusions, select = traits[[trait]]), check.keys = TRUE)$total$raw_alpha, "is rated as good rel.\n")
}
# Define the columns for each trait
traits <- list(
Agreeableness = c("bfi_a1", "bfi_a2", "bfi_a3", "bfi_a4", "bfi_a5", "bfi_a6", "bfi_a7", "bfi_a8", "bfi_a9"),
Conscientiousness = c("bfi_c1", "bfi_c2", "bfi_c3", "bfi_c4", "bfi_c5", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9"),
Extraversion = c("bfi_e1", "bfi_e2", "bfi_e3", "bfi_e4", "bfi_e5", "bfi_e6", "bfi_e7", "bfi_e8"),
Neuroticism = c("bfi_n1", "bfi_n2", "bfi_n3", "bfi_n4", "bfi_n5", "bfi_n6", "bfi_n7", "bfi_n8"),
Openness = c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7", "bfi_o8", "bfi_o9", "bfi_o10")
)
# Loop through each trait to calculate alpha
for (trait in names(traits)) {
alpha_result <- alpha(subset(data_processed_after_exclusions, select = traits[[trait]]))
cat(trait, ": raw_alpha ", alpha_result$total$raw_alpha, "is rated as good rel.\n")
}
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
install.packages(c("askpass", "BayesFactor", "brew", "brio", "bslib", "checkmate", "cli", "cluster", "credentials", "curl", "data.table", "datawizard", "DBI", "dbplyr", "desc", "deSolve", "digest", "dplyr", "emmeans", "evaluate", "fansi", "fontawesome", "foreign", "fs", "gert", "GGally", "ggplot2", "ggrepel", "ggridges", "glue", "gnm", "GPArotation", "gtools", "haven", "htmltools", "htmlwidgets", "httpuv", "httr", "httr2", "insight", "jmv", "jmvcore", "jsonlite", "KernSmooth", "knitr", "later", "lattice", "lavaan", "learnr", "lme4", "lubridate", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "mvtnorm", "nlme", "openssl", "patchwork", "pkgbuild", "pkgload", "plyr", "prettyunits", "processx", "progress", "promises", "psych", "purrr", "quantreg", "R.utils", "ragg", "Rcpp", "RcppEigen", "RCurl", "readr", "readxl", "rematch", "remotes", "report", "reprex", "reticulate", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rstudioapi", "sandwich", "sass", "scales", "shiny", "spatial", "stringi", "stringr", "survival", "svglite", "systemfonts", "testthat", "textshaping", "tinytex", "utf8", "vcd", "vcdExtra", "vctrs", "vipor", "vroom", "waldo", "xfun", "xml2", "yaml", "yulab.utils"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
install.packages(c("cli", "digest", "htmltools", "MASS", "Matrix", "rlang", "roxygen2", "xfun"))
install.packages(c("cli", "digest", "htmltools", "MASS", "Matrix", "rlang", "roxygen2", "xfun"))
knitr::opts_chunk$set(echo = TRUE)
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
install.packages("htmltools")
install.packages("htmltools")
library("htmltools")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library("htmltools")
data_processed <- read_csv("../data/processed/data_processed.csv")
# Exclude participants using the master exclusion variable.
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |>
kable_classic(full_width = FALSE)
library("htmltools")
install.packages(c("cli", "digest", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "digest", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "digest", "htmltools", "rlang", "xfun"))
install.packages(c("cli", "digest", "htmltools", "rlang", "xfun"))
