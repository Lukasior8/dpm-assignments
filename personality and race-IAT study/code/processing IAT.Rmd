---
title: "Examining the relationship between the big-5 personality facets and implicit racial attitudes"
subtitle: "processing IAT"
author: "Lukas Sidler"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Dependancies
```{r}
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)

```

# Read Demographics data

```{r}
data_demographics <- read.csv("../data/raw/data_raw_demographics.csv") %>% 
janitor::clean_names()
```
# Read IAT Data
```{r}
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv")
#getting rid of first row because it contains unnecessarry titles
data_iat_raw <- data_iat_raw[-1, ] %>%
  janitor::clean_names()
```
# Read Personality Data
```{r}
data_personality <- read_csv("../data/raw/data_raw_bfi.csv")  %>% 
  janitor::clean_names()
```
# Demographics
The data set was produced by a study which asked each participant to complete (a) between 2 and 3 of the big-5 personality subscales, (b) an Implicit Association Test assessing implicit racial evaluations between African-American and European-American people, an (c) demographics data including age and gender. Note that providing demographics data was optional, so missing demographics data does not constitute incomplete data. 


## Extract age and gender from the raw demographics data.
```{r}
data_age_sex <- data_demographics  %>% 
  distinct(unique_id, variable, .keep_all = TRUE) %>% 
  pivot_wider(id_cols = unique_id,
              names_from = variable,
              values_from = response) %>%  
  mutate(unique_id = as.character(unique_id),
         age = as.numeric(age),
         sex = as.character(sex))

```

# BFI
## Reverse score the negatively worded items:
the extroversion scale items 2, 5 and 7, conscientiousness items 2, 4 5 and 9, neuroticism items 2, 5, and 7, agreeableness 1, 3, 6, and 8, and openness items 7 and 9.

```{r}
#using recode to manually reverse all the neccessary items
data_personality_reversed <- data_personality %>% 
  mutate(bfi_e2 = recode(bfi_e2, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1), 
         bfi_e5 = recode(bfi_e5, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_e7 = recode(bfi_e7, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_c2 = recode(bfi_c2, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_c4 = recode(bfi_c4, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_c5 = recode(bfi_c5, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_c9 = recode(bfi_c9, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_n2 = recode(bfi_n2, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_n5 = recode(bfi_n5, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_n7 = recode(bfi_n7, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_a1 = recode(bfi_a1, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_a3 = recode(bfi_a3, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_a6 = recode(bfi_a6, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_a8 = recode(bfi_a8, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_o7 = recode(bfi_o7, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         bfi_o9 = recode(bfi_o9, "1" = 6, "2" = 5, "3" = 4, "4" = 3, "5" = 2, "6" = 1),
         unique_id = as.character(unique_id))


```

## Sanitycheck for reversals
### extraversion

```{r}
# Subset the dataset for extraversion items
extroversion_items <- data_personality_reversed %>% 
  select(starts_with("bfi_e"))

# Calculate the correlation matrix
correlation_extroversion <- cor(extroversion_items, use = "complete.obs")

# View the correlation matrix
print(correlation_extroversion)

# Check for any negative correlations
any_negative_correlations_extroversion <- any(correlation_extroversion < 0)

# Print result of the check
print(any_negative_correlations_extroversion)

#If any_negative_correlations returns TRUE for any subscale, it suggests there might be an issue with the item reversals or the data itself, and further investigation would be required. In this case the correlation bfi_o7 x bfi_o10 is negative.
```

### Conscientiousness

```{r}
# Subset the dataset for extraversion items
Conscientiousness_items <- data_personality_reversed %>% 
  select(starts_with("bfi_c"))

# Calculate the correlation matrix
correlation_Conscientiousness <- cor(Conscientiousness_items, use = "complete.obs")

# View the correlation matrix
print(correlation_Conscientiousness)

# Check for any negative correlations
any_negative_correlations_Conscientiousness <- any(correlation_Conscientiousness < 0)

# Print result of the check
print(any_negative_correlations_Conscientiousness)

#If any_negative_correlations returns TRUE for any subscale, it suggests there might be an issue with the item reversals or the data itself, and further investigation would be required.
```
### Neuroticism

```{r}
# Subset the dataset for extraversion items
Neuroticism_items <- data_personality_reversed %>% 
  select(starts_with("bfi_n"))

# Calculate the correlation matrix
correlation_Neuroticism <- cor(Neuroticism_items, use = "complete.obs")

# View the correlation matrix
print(correlation_Neuroticism)

# Check for any negative correlations
any_negative_correlations_Neuroticism <- any(correlation_Neuroticism < 0)

# Print result of the check
print(any_negative_correlations_Neuroticism)

#If any_negative_correlations returns TRUE for any subscale, it suggests there might be an issue with the item reversals or the data itself, and further investigation would be required.
```

### Agreeableness

```{r}
# Subset the dataset for extraversion items
Agreeableness_items <- data_personality_reversed %>% 
  select(starts_with("bfi_a"))

# Calculate the correlation matrix
correlation_Agreeableness <- cor(Agreeableness_items, use = "complete.obs")

# View the correlation matrix
print(correlation_Agreeableness)

# Check for any negative correlations
any_negative_correlations_Agreeableness <- any(correlation_Agreeableness < 0)

# Print result of the check
print(any_negative_correlations_Agreeableness)

#If any_negative_correlations returns TRUE for any subscale, it suggests there might be an issue with the item reversals or the data itself, and further investigation would be required.
```
### Openness to Experience

```{r}
# Subset the dataset for extraversion items
OE_items <- data_personality_reversed %>% 
  select(starts_with("bfi_o"))

# Calculate the correlation matrix
correlation_OE <- cor(OE_items, use = "complete.obs")

# View the correlation matrix
print(correlation_OE)

# Check for any negative correlations
any_negative_correlations_OE <- any(correlation_OE < 0)

# Print result of the check
print(any_negative_correlations_OE)



#If any_negative_correlations returns TRUE for any subscale, it suggests there might be an issue with the item reversals or the data itself, and further investigation would be required.In this case the correlation bfi_o7 x bfi_o10 is negative.
```

## Check that the item level data does not violate the logical minimum and maximum scores (1 to 6).

Create an exclusion variable and set participants with impossible data to "exclude". 

```{r}
# Check if any item is outside the range 1 to 6 and is not NA
data_personality_reversed_likert <- data_personality_reversed %>%
  rowwise() %>%
  mutate(is_likert = ifelse(any(c_across(starts_with("bfi_")) < 1 | 
                             c_across(starts_with("bfi_")) > 6, na.rm = TRUE), "exclude", "include")) %>%
  ungroup()
##na.rm = TRUE ensures that missing values (NA) are ignored in this calculation.
# View the first few rows of the modified dataset
head(data_personality_reversed_likert)

```

## Check that all participants have complete data on the BFI scales they completed.
Create an exclusion variable and set participants with incomplete data to "exclude".



```{r}

# Function to check for missing values in a scale and create an exclusion flag
check_and_flag_missing_data <- function(data, scale_prefix) {
  scale_items <- select(data, starts_with(scale_prefix))
  flag <- ifelse(rowSums(is.na(scale_items)) > 0, "exclude", "include")
  return(flag)
}

# Apply the function to each BFI scale and add exclusion flags to the dataset
data_bfi_completed <- data_personality_reversed_likert %>%
  mutate(
    complete_criteria_a = check_and_flag_missing_data(., "BFI_a"),
    complete_criteria_c = check_and_flag_missing_data(., "BFI_c"),
    complete_criteria_e = check_and_flag_missing_data(., "BFI_e"),
    complete_criteria_n = check_and_flag_missing_data(., "BFI_n"),
    complete_criteria_o = check_and_flag_missing_data(., "BFI_o")  # Explicitly checking for BFI_o
  )

# View the first few rows of the modified dataset
head(data_bfi_completed)

```


## Mean-score the subscales of the BFI scale.
Each participant only got either 2 or 3 subscales. 

```{r}


# Calculate mean scores for participants with complete data

data_bfi_mean_scores <- data_bfi_completed %>%
  rowwise() %>%
  mutate(
    agreeableness_mean = ifelse(complete_criteria_a == "include", mean(c_across(starts_with("BFI_a")), na.rm = TRUE), NA),
    conscientiousness_mean = ifelse(complete_criteria_c == "include", mean(c_across(starts_with("BFI_c")), na.rm = TRUE), NA),
    extraversion_mean = ifelse(complete_criteria_e == "include", mean(c_across(starts_with("BFI_e")), na.rm = TRUE), NA),
    neuroticism_mean = ifelse(complete_criteria_n == "include", mean(c_across(starts_with("BFI_n")), na.rm = TRUE), NA),
    openness_mean = ifelse(complete_criteria_o == "include", mean(c_across(starts_with("BFI_o")), na.rm = TRUE), NA)
  ) %>%
  ungroup()

# View the modified dataset
head(data_bfi_mean_scores)
```


```{r}
#calculate overall mean scores 


# Calculate the overall mean for each BFI subscale
data_bfi_overall_mean_scores <- data_bfi_mean_scores %>%
  summarise(
    overall_mean_agreeableness = mean(agreeableness_mean, na.rm = TRUE),
    overall_mean_conscientiousness = mean(conscientiousness_mean, na.rm = TRUE),
    overall_mean_extraversion = mean(extraversion_mean, na.rm = TRUE),
    overall_mean_neuroticism = mean(neuroticism_mean, na.rm = TRUE),
    overall_mean_openness = mean(openness_mean, na.rm = TRUE)
  )

# View the overall mean scores
data_bfi_overall_mean_scores

```

## Check that the mean scores do not violate the min and max possible score 
(i.e., first determine this min and max score), and revise your scoring code if it does.

```{r}
#values can be between 1 and 6 for each item. so min should be 1 and max should be 6

#liket scale ranging from 1 to 6
minimal_possible_score <- 1
maximal_possible_score <- 6

# Check if any mean scores violate the min and max possible scores
violations <- data_bfi_mean_scores %>%
  summarise(
    violation_in_agreeableness = any(agreeableness_mean < minimal_possible_score | agreeableness_mean > maximal_possible_score, na.rm = TRUE),
    violation_in_conscientiousness = any(conscientiousness_mean < minimal_possible_score | conscientiousness_mean > maximal_possible_score, na.rm = TRUE),
    violation_in_extraversion = any(extraversion_mean < minimal_possible_score | extraversion_mean > maximal_possible_score, na.rm = TRUE),
    violation_in_neuroticism = any(neuroticism_mean < minimal_possible_score | neuroticism_mean > maximal_possible_score, na.rm = TRUE),
    violation_in_openness = any(openness_mean < minimal_possible_score | openness_mean > maximal_possible_score, na.rm = TRUE)
  )

# View the violations
violations

#as you can see in the results, all are FALSE, aka none of the means violates the minium or maximum value

```
# IAT

## Score the trial-level IAT data using the Greenwald "D" score:
Calculate a mean RT ("mean1") for blocks 3 and 6 (one score using trials from both blocks), a mean RT ("mean2") for blocks 4 and 7 (one score using trials from both blocks), and the SD of RTs in blocks 3, 4, 6 and 7 ("SD"). To calculate D: D = (mean2 - mean1)/SD. Blocks 1, 2, and 5 are practice blocks and must be discarded. 

```{r}

# Load dataset and convert necessary columns to numeric and filter necessary ones

data_iat <- data_iat_raw %>%
  mutate(
    block = as.numeric(as.character(block)),
    participant = as.numeric(as.character(participant)),
    reaction_time = as.numeric(as.character(x6)), 
    category = as.character(x3),
    reactiontime = as.numeric(x6),
    response = as.character(x5),
    trial = as.character(trial)
  ) %>%
  filter(block %in% c(3, 4, 6, 7), response == "correct") %>%
  select(
    participant,  
    block,
    category,
     trial,
       response,
    reaction_time
  )



# Calculate the "D" score using the specified blocks
iat_d_scores <- data_iat %>%
  group_by(participant) %>%
  # Calculate means and SD within one summarise call
  summarise(
    mean1 = mean(reaction_time[block %in% c(3, 6)], na.rm = TRUE),
    mean2 = mean(reaction_time[block %in% c(4, 7)], na.rm = TRUE),
    SD = sd(reaction_time[block %in% c(3, 4, 6, 7)], na.rm = TRUE),
    .groups = 'drop'  # This ensures the data is ungrouped after summarize
  ) %>%
  # Calculate the D score immediately after summarising
  mutate(D = (mean2 - mean1) / SD)

# View the resulting scores
iat_d_scores

#Join back to main dataset
data_iat_dscores <- data_iat %>%
  left_join(iat_d_scores, by = "participant")


```

## Include a sanity check: 
check that all D scores are in the range -2 to +2. If not, revise your implementation of the scoring code.

```{r}
# Sanity check: Check if all D scores are within the range -2 to +2
d_score_out_of_range <- any(data_iat_dscores$D < -2 | data_iat_dscores$D > 2)
# If there are D scores out of range, this will print a warning message
if (d_score_out_of_range) {
  warning("Some D scores are outside the range of -2 to +2. Please revise your scoring implementation.")
}
# View the D scores and the result of the sanity check
list(iat_d_scores, d_score_out_of_range)

```

## Create an exclusion variable 
and set participants with incomplete trial level IAT data to "exclude". 
Specifically, IAT should have 120 trials on the critical test blocks (i.e., blocks 3, 4, 6 and 7). Trials on the other (practice) blocks can be discarded.

```{r}

# Create the exclusion variable based on trial completeness
data_iat_dscores_with_exclusion <- data_iat_dscores %>%
  # Filter out practice blocks
  filter(block %in% c(3, 4, 6, 7)) %>%
  # Count the number of trials per participant in critical blocks
  group_by(participant) %>%
  summarise(trials_in_critical_blocks = n()) %>%
  # Create the exclusion variable
  mutate(exclusion_trial = ifelse(trials_in_critical_blocks < 120, "exclude", "include")) %>%
  ungroup()
# Join the exclusion data back to the main dataset
data_iat_dscores_with_exclusion <- data_iat_dscores %>%
  left_join(data_iat_dscores_with_exclusion, by = "participant")
# View the dataset with exclusion variable
head(data_iat_dscores_with_exclusion)



#here i tried to check how many trials per person exist.... however almost all the participants have fewer than 120 trials in the critical blocks!

# Calculate the number of trials per participant in critical blocks
trials_per_participant <- data_iat_dscores %>%
  # Filter out practice blocks and keep only critical blocks
  filter(block %in% c(3, 4, 6, 7)) %>%
  # Count the number of trials per participant in critical blocks
  group_by(participant) %>%
  summarise(trials_in_critical_blocks = n()) %>%
  ungroup()

# Join the trials count data back to the main dataset
data_iat_dscores_with_trial_count <- data_iat_dscores %>%
  left_join(trials_per_participant, by = "participant")

# View the dataset with the new variable
head(data_iat_dscores_with_trial_count)







```

## Create an exclusion variable for IAT performance:
set participants with >10% of the participants trials are < 300ms, or if their accuracy is < than 75%. Only use trials from the critical test blocks when computing these (i.e., blocks 3, 4, 6 and 7).

```{r}

# Create the performance exclusion variable
data_iat_new <- data_iat_dscores_with_exclusion %>%
  filter(block %in% c(3, 4, 6, 7)) %>% # Filter to only include critical test blocks
  mutate(
    reaction_time = as.numeric(as.character(reaction_time)),
    response = response == "correct" # Correctly convert accuracy to logical
  ) %>%
  group_by(participant) %>%
  summarise(
    pct_fast_trials = mean(reaction_time < 300, na.rm = TRUE),
    overall_accuracy = mean(response, na.rm = TRUE) # Use accuracy here
  ) %>%
  mutate(
    exclusion_performance = if_else(pct_fast_trials > 0.10 | overall_accuracy < 0.75, "exclude", "include")
  ) %>%
  ungroup()
# Join the performance exclusion data back to the main dataset
data_iat_complete <- data_iat_dscores_with_exclusion %>%
  left_join(data_iat_new, by = "participant")
# View the dataset with performance exclusion variable
head(data_iat_complete)
head(data_iat_new)



options(max.print=100)

```

# Combine the demographics, BFI, and IAT data into one data frame.
This data frame should be one-row-one-participant. Both the mean scored and item level BFI data should be present in the dataset.

```{r}


#First we rename unique_id in data_age_sex and, data_bfi_mean_scores to “participant” so that we can join them by participant
data_age_sex_rdy4merge <- data_age_sex %>%
  rename(participant = unique_id)
data_bfi_mean_scores_ready4merge <- data_bfi_mean_scores %>%
  rename(participant = unique_id)
library(tidyverse)
# Check the type of the participant column in each data frame
str(data_age_sex_rdy4merge$participant)
str(data_bfi_mean_scores_ready4merge$participant)
str(data_iat_complete$participant)
# If necessary, convert the participant column to character in all data frames
data_age_sex_rdy4merge$participant <- as.numeric(data_age_sex_rdy4merge$participant)
data_bfi_mean_scores_ready4merge$participant <- as.numeric(data_bfi_mean_scores_ready4merge$participant)
data_iat_complete$participant <- as.numeric(data_iat_complete$participant)
# join the datasets
data_merged_before_exclusions <- data_age_sex_rdy4merge %>%
  full_join(data_bfi_mean_scores_ready4merge, by = "participant") %>%
  full_join(data_iat_complete, by = "participant")

unique_participants_data <- data_merged_before_exclusions %>% distinct(participant, .keep_all = TRUE)


```


# Create a master exclude variable from the individual exclude variables. 

```{r}

# create a master exclude_participant variable
data_processed <- unique_participants_data %>% 
  mutate(exclude_participant = case_when(is.na(age) ~ "exclude", 
                                         is.na(sex) ~ "exclude",
                                         is.na(participant) ~"exclude",
                                         is_likert == "exclude" ~ "exclude",
                                         #exclusion_trial == "exclude" ~ "exclude", I wont exclude participants with fewer than 120 triasls, because otherwise there would only be 9 participants after exclusions making the analysis unusable.
                                         exclusion_performance == "exclude" ~ "exclude",
                                        TRUE ~ "include"))



```


# Save the processed data to the data/processed/ folder as "data_processed.csv". 

```{r}

getwd()

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")











```


# Create a codebook for the processed data file that explains what each variable represents.

```{r}

# if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
#   # convert the column names to a df
#   codebook_template <- data.frame(variable = colnames(data_processed)) |>
#     mutate(explanation = NA)
#   # write to disk as an excel file
#   write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
# }

```


# Session info

```{r}
# This line of code calls the 'sessionInfo()' function in R, which displays information about the current R session, including the R version, operating system, and loaded packages and their versions.

sessionInfo()

```

