###is it possible to have a square automatically? ian sais to keep the dimensions
#split histogram
# Create the base plot
splithistogramv1 <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, fill = gender)) +
geom_histogram(position = "dodge", binwidth = 0.15) + # Adjust binwidth as needed
facet_grid(. ~ gender) + # Splitting the histogram by gender
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_minimal()
# Add marginal histograms (if needed)
# ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
# Print the plot
print(splithistogramv1)
# Create the split violin plot
splitviolinv1 <- ggplot(data_processed_after_exclusions, aes(x = gender, y = AMP_score, fill = gender)) +
geom_violin(scale = "area", trim = FALSE) + # Violin plot
geom_boxplot(width = 0.1, fill = "white") + # Add a boxplot inside the violin
facet_wrap(~gender, scales = "free_x") + # Splitting by gender
xlab("Gender") +
ylab("AMP Score") +
theme_minimal()
# Print the plot
print(splitviolinv1)
# Load necessary libraries
library(ggplot2)
install.packages("ggbeeswarm")
library(ggbeeswarm) # for geom_quasirandom
# Create the raincloud plot
raincloudplotv1 <- ggplot(data_processed_after_exclusions, aes(x = gender, y = AMP_score, fill = gender)) +
# Add a half violin plot
geom_violin(trim = FALSE, scale = "area", adjust = 1.5, alpha = 0.5) +
# Add the boxplot
geom_boxplot(width = 0.1, outlier.shape = NA, alpha = 0.5) +
# Add points
geom_quasirandom(aes(color = gender), size = 2, alpha = 0.5, show.legend = FALSE) +
# Customizations
scale_color_brewer(palette = "Dark2") +
scale_fill_brewer(palette = "Dark2") +
labs(x = "Gender", y = "AMP Score") +
theme_minimal()
# Print the plot
print(raincloudplotv1)
####ians commnt maybe remove legend, because over explained
splithistogramv2 <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, fill = gender)) +
geom_histogram(position = "dodge", binwidth = 0.15) + # Adjust binwidth as needed
facet_grid(. ~ gender) + # Splitting the histogram by gender
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
scale_fill_manual(values = c("male" = "blue", "female" = "red", "nonbinary" = "green"),
labels = c("Men", "Women", "Nonbinary"),
breaks = c( "female", "male", "nonbinary")) +
theme_minimal()
# Print the plot
print(splithistogramv2)
splithistogramv2 <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, fill = gender)) +
geom_histogram(position = "dodge", binwidth = 0.15) + # Adjust binwidth as needed
facet_grid(. ~ gender) + # Splitting the histogram by gender
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
scale_fill_manual(values = c("male" = "blue", "female" = "red", "nonbinary" = "green"),
labels = c("Men", "Women", "Nonbinary"),
breaks = c( "female",  "nonbinary", "male")) +
theme_minimal()
# Print the plot
print(splithistogramv2)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
group_by(subject) |>
count() |>
ungroup() |>
mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
select(-n)
# data_amp_completeness |>
#   count(n)
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
data_amp_score_congruence <- data_amp_raw |>
select(subject, evaluative_response = correct, trialcode, blockcode) |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(trialcode = case_when(trialcode == "prime_positive" ~ 1,
trialcode == "prime_negative" ~ 0,
TRUE ~ NA),
prime_congruence = ifelse(trialcode == evaluative_response, 1, 0))
# sanity check 1: if you consider all the combiantions of factor levels of trialcode, evaluative_response, and prime congruence, there should be only 4:
data_amp_score_congruence |>
count(trialcode, evaluative_response, prime_congruence)
data_amp_score_congruence |>
count(trialcode, evaluative_response, prime_congruence) |>
nrow() == 4
# calculate AMP score
data_amp_score <- data_amp_score_congruence |>
group_by(subject) |>
summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |>
select(subject, AMP_score)
# sanity check 2: check if AMP_score is numeric
is.numeric(data_amp_score$AMP_score)
# sanity check 3: check if AMP_score is bounded [0,1]
data_amp_score |>
mutate(bounded_correctly = between(AMP_score, left = 0, right = 1)) |>
filter(bounded_correctly != TRUE) |>
nrow() == 0
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_score, by = "subject") |>
full_join(data_amp_performance_criteria, by = "subject") |>
full_join(data_amp_completeness, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
exclude_amp_completeness == "exclude" ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
library(openxlsx)
if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
# convert the column names to a df
codebook_template <- data.frame(variable = colnames(data_processed)) |>
mutate(explanation = NA)
# write to disk as an excel file
write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}
sessionInfo()
# The code creates three different types of plots to visualize the distribution of AMP scores by gender in 'data_processed_after_exclusions'.
1. 'splithistogramv1': A split histogram with histograms for each gender category, using 'facet_grid' for separation and 'geom_histogram' with a dodge position. It is styled with 'theme_minimal'.
# This code configures options for R Markdown knitting and the R session. It sets knitr chunk options to suppress messages and warnings during knitting, and alters the R session option 'scipen' to disable scientific notation, favoring full numeric representation.
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
# This code loads various R libraries: 'tidyverse' for data manipulation, 'knitr' and 'kableExtra' for formatting tables, 'janitor' for data cleaning, 'scales' and 'gridExtra' for plotting adjustments, 'ggplot2' and 'ggExtra' for enhanced graphical capabilities, and 'devtools' for development tasks.
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(gridExtra)
library(ggplot2)
library(ggExtra)
library(devtools)
# This code reads the 'data_processed.csv' file into R, creating a dataframe 'data_processed'. Then it filters this dataframe to include only those rows where 'exclude_participant' is marked as "include", resulting in a new dataframe 'data_processed_after_exclusions'.
data_processed <- read_csv("../data/processed/data_processed.csv")
data_processed_after_exclusions <- data_processed |>
filter(exclude_participant == "include")
# This code counts the number of rows in the 'data_processed' dataframe and formats the result as a table using 'kable' and 'kable_classic' functions. It adds a header row titled "Whole sample" above the table. The header spans one column, as indicated by the value "1" in the header argument.
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
# This code counts the number of rows in the 'data_processed_after_exclusions' dataframe and displays this count in a table using the 'kable' function. It adds a header row with the title "For analysis", spanning one column, and applies the 'kable_classic' style with 'full_width' set to FALSE for table formatting.
data_processed_after_exclusions |>
count(name = "n") |>
kable() |>
add_header_above(header = c("For analysis" = 1)) |>
kable_classic(full_width = FALSE)
# This code processes 'data_processed_after_exclusions', converts the 'age' column to numeric, and calculates the mean and standard deviation (SD) of age, excluding missing values. The results are rounded to one decimal place using 'janitor::round_half_up'. The data is then displayed in a table with 'kable' and styled using 'kable_classic', including a header row titled "Age" spanning two columns.
data_processed_after_exclusions |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# This code processes the 'data_processed_after_exclusions' dataset by renaming the 'gender' column to 'Gender'. It then groups the data by gender and calculates the count and percentage of each gender category. The gender names are formatted to sentence case for better presentation. The resulting data is displayed in a table using 'kable' with 'kable_class
data_processed_after_exclusions |>
rename(Gender = gender) |>
group_by(Gender) |>
summarise(n = n()) |>
mutate(Percent = paste0(round_half_up((n / sum(n)) * 100, 1), "%")) |>
mutate(Gender = stringr::str_to_sentence(Gender)) |> # Change the case of the Gender variable so that it prints nicely
kable() |>
kable_classic(full_width = FALSE)
# This code calculates and combines self-reported evaluation statistics for the full sample and by gender category. It first computes the mean, standard deviation (SD), and count (n) for the full sample, then repeats this process grouping by gender. The results from both calculations are combined into one table, selecting and renaming relevant columns. The column names are formatted for better presentation, and numeric values are rounded to two decimal places. The final table is displayed using 'kable' with a header and 'kable_classic' styling.
# overall self-reported evaluations
dat_mean_ratings <- data_processed_after_exclusions |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE),
n = n()) |>
mutate(group = "Full sample")
# self-reported evaluations by gender category
dat_mean_ratings_by_gender <- data_processed_after_exclusions |>
group_by(group = gender) |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE),
n = n())
# combine both into one table
bind_rows(dat_mean_ratings,
dat_mean_ratings_by_gender) |>
select(Subset = group, Mean, SD, n) |> # select variables of interest, and rename one
mutate(Subset = stringr::str_to_sentence(Subset)) |> # Change the case of the Subset variable so that it prints nicely
mutate_if(is.numeric, round_half_up, digits = 2) |>
kable() |>
add_header_above(header = c(" " = 1, "Self-reported evaluations" = 3)) |>
kable_classic(full_width = FALSE)
# This code creates a histogram using 'ggplot2' to visualize the distribution of mean self-reported evaluations in the 'data_processed_after_exclusions' dataset. The histogram's bins are set to a width of 0.05, and colors are defined using the 'viridis' palette. The x-axis is labeled as "Mean self-reported evaluation", and the y-axis as "Frequency". The plot uses the 'theme_linedraw' for a clean look, and the x-axis scale is adjusted for better readability with 'pretty_breaks'.
ggplot(data_processed_after_exclusions, aes(x = mean_evaluation)) +
geom_histogram(binwidth = 0.05,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("Mean self-reported evaluation") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))
# This code generates descriptive statistics for self-reported evaluations in the 'data_processed_after_exclusions' dataset, both for the full sample and by gender. It computes the mean, standard deviation (SD), and count (n) for these groups. The results are combined into one table, with columns selected and renamed for clarity. Numeric values are rounded to two decimal places for presentation. The final table is formatted using 'kable' with an added header row and 'kable_classic' styling for a polished look.
### Descriptive stats
# all self evluations
dat_mean_ratings <- data_processed_after_exclusions |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE),
n = n()) |>
mutate(group = "Full sample")
# by gender
dat_mean_ratings_by_gender <- data_processed_after_exclusions |>
group_by(group = gender) |>
summarise(Mean = mean(mean_evaluation, na.rm = TRUE),
SD = sd(mean_evaluation, na.rm = TRUE),
n = n())
# combine
bind_rows(dat_mean_ratings,
dat_mean_ratings_by_gender) |>
select(Subset = group, Mean, SD, n) |>
mutate(Subset = stringr::str_to_sentence(Subset)) |>
mutate_if(is.numeric, round_half_up, digits = 2) |>
kable() |>
add_header_above(header = c(" " = 1, "AMP evaluation" = 3)) |>
kable_classic(full_width = FALSE)
# This code creates a histogram for the 'AMP_score' variable in the 'data_processed_after_exclusions' dataset using 'ggplot2'. The histogram's bin width is set to 0.05 with custom fill and color using the 'viridis' palette. The x-axis is labeled as "AMP score", and the y-axis as "Frequency". It uses 'theme_linedraw' for styling, with a modification to make the grid lines less prominent, as per Ian's feedback. The x-axis scale is adjusted for readability using 'pretty_breaks'.
ggplot(data_processed_after_exclusions, aes(x = AMP_score)) +
geom_histogram(binwidth = 0.05,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("AMP score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 10))
##ians feedback: make grid less strong
# The code creates four scatter plots using 'ggplot2' to visualize the relationship between AMP scores and mean self-reported evaluations in the 'data_processed_after_exclusions' dataset. Each plot uses 'geom_jitter' for point dispersion and 'viridis_pal' for color. The first two plots include a linear model fit ('geom_smooth') to indicate trends. The third plot switches axes, plotting AMP score on the y-axis and mean evaluation on the x-axis. The fourth plot is a basic jitter plot without the linear model fit. All plots are styled with 'theme_linedraw' for a clean appearance.
ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggplot(data_processed_after_exclusions,
aes(y = AMP_score,
x = mean_evaluation)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) +
ylab("AMP score") +
xlab("Mean self-reported evaluation") +
theme_linedraw()
ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
# The code creates a scatter plot 'scatterplotv1' using 'ggplot2', showing the relationship between AMP scores and mean self-reported evaluations from 'data_processed_after_exclusions', with data points colored by gender. 'geom_jitter' is used to add variability to the point positions, enhancing visibility. Marginal histograms for both axes are added using 'ggMarginal', with grouping by color. The plot is printed at the end. The comments suggest adjusting the legend location and using customized colors instead of default ones for better visual appeal.
scatterplotv1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
ggMarginal(scatterplotv1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
print(scatterplotv1)
### ggplot legend location, maybe inside the plot or besides and fiddle with the
# dont use generic simple default, use customized colours
# The code constructs a scatter plot 'pointslabeldgraph' using 'ggplot2' with AMP scores on the x-axis and mean self-reported evaluations on the y-axis, labeling points with the 'subject' identifier. It uses 'geom_jitter' for point dispersion with colors from the 'viridis' palette. 'geom_text_repel' from the 'ggrepel' package is used to add labels to points with AMP scores more than two standard deviations away from the mean (|z| > 2), enhancing readability and focus on outliers. The plot is styled with 'theme_linedraw' for a clean appearance.
library(viridis) # If you are using viridis for color scales
library(ggrepel)
z_threshold = 2
pointslabeldgraph <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score, y = mean_evaluation, label = subject)) + # Add label aesthetic
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
#geom_text_repel() + # Add this line for labels
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
pointslabeldgraph + geom_text_repel(data = filter(data_processed_after_exclusions, abs(scale(AMP_score)) > z_threshold),
aes(label = subject))
# The code creates a scatter plot 'ggp' using 'ggplot2', visualizing the relationship between AMP scores and mean self-reported evaluations from 'data_processed_after_exclusions'. It uses 'geom_jitter' for point dispersion and the 'viridis' color palette. The plot is styled with 'theme_linedraw'. A magnified inset is added using 'geom_magnify' from the 'ggmagnify' package, focusing on a specific region defined in the 'from' parameter. The location of the magnified inset on the plot is controlled by the 'to' parameter. The comment inquires about maintaining a square aspect ratio for the magnified area, which is important for preserving the scale and proportions in the magnified view.
# Load necessary libraries
library(ggplot2)
library(ggmagnify)
library(viridis)
# Your original scatter plot
ggp <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, y = mean_evaluation)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1), alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
# Define the area to be magnified
# Adjust these values to the area you want to zoom in on
from <- c(xmin = 0.3, xmax = 0.8, ymin = 0.8, ymax = 1.3)
# Define where to place the magnified inset on the plot
# Adjust these values to place the inset where you like
to <- c(xmin = 0, xmax = 0.25, ymin = 4, ymax = 5)
# Add the magnified area to the plot
ggp + geom_magnify(from = from, to = to)
###is it possible to have a square automatically? ian sais to keep the dimensions
# # The code creates three different types of plots to visualize the distribution of AMP scores by gender in 'data_processed_after_exclusions'.
#
# 1. 'splithistogramv1': A split histogram with histograms for each gender category, using 'facet_grid' for separation and 'geom_histogram' with a dodge position. It is styled with 'theme_minimal'.
#
# 2. 'splitviolinv1': A split violin plot, featuring violin plots and embedded boxplots for each gender category, using 'facet_wrap' for separation. It is also styled with 'theme_minimal'.
#
# 3. 'raincloudplotv1': A raincloud plot combining half violin plots, boxplots, and quasirandom points to show the distribution of AMP scores by gender. This plot uses 'geom_violin', 'geom_boxplot', and 'geom_quasirandom' from the 'ggbeeswarm' package. The plot omits the legend as per Ian's suggestion for simplicity, given the redundancy with the fill and color coding.
#
# Each plot is designed to provide a distinct visual representation of the data, offering different perspectives on the distribution and variability of AMP scores across genders.
#split histogram
# Create the base plot
splithistogramv1 <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, fill = gender)) +
geom_histogram(position = "dodge", binwidth = 0.15) + # Adjust binwidth as needed
facet_grid(. ~ gender) + # Splitting the histogram by gender
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_minimal()
# Add marginal histograms (if needed)
# ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
# Print the plot
print(splithistogramv1)
# Create the split violin plot
splitviolinv1 <- ggplot(data_processed_after_exclusions, aes(x = gender, y = AMP_score, fill = gender)) +
geom_violin(scale = "area", trim = FALSE) + # Violin plot
geom_boxplot(width = 0.1, fill = "white") + # Add a boxplot inside the violin
facet_wrap(~gender, scales = "free_x") + # Splitting by gender
xlab("Gender") +
ylab("AMP Score") +
theme_minimal()
# Print the plot
print(splitviolinv1)
# Load necessary libraries
library(ggplot2)
library(ggbeeswarm) # for geom_quasirandom
# Create the raincloud plot
raincloudplotv1 <- ggplot(data_processed_after_exclusions, aes(x = gender, y = AMP_score, fill = gender)) +
# Add a half violin plot
geom_violin(trim = FALSE, scale = "area", adjust = 1.5, alpha = 0.5) +
# Add the boxplot
geom_boxplot(width = 0.1, outlier.shape = NA, alpha = 0.5) +
# Add points
geom_quasirandom(aes(color = gender), size = 2, alpha = 0.5, show.legend = FALSE) +
# Customizations
scale_color_brewer(palette = "Dark2") +
scale_fill_brewer(palette = "Dark2") +
labs(x = "Gender", y = "AMP Score") +
theme_minimal()
# Print the plot
print(raincloudplotv1)
####ians commnt maybe remove legend, because over explained
# The code creates 'splithistogramv2', a split histogram plot using 'ggplot2' to visualize AMP score distributions by gender in the 'data_processed_after_exclusions' dataset. It features histograms for each gender category, arranged side by side using 'facet_grid'. The histogram bins are positioned using 'dodge' and the binwidth is set to 0.15. The plot is labeled with appropriate x and y-axis labels. The 'scale_fill_manual' function customizes the color scheme (blue for males, red for females, green for nonbinary individuals) and the legend, with labels for each gender category and a specified order for the legend entries. The plot is styled with 'theme_minimal' for a clean and straightforward visual presentation.
splithistogramv2 <- ggplot(data_processed_after_exclusions, aes(x = AMP_score, fill = gender)) +
geom_histogram(position = "dodge", binwidth = 0.15) + # Adjust binwidth as needed
facet_grid(. ~ gender) + # Splitting the histogram by gender
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
scale_fill_manual(values = c("male" = "blue", "female" = "red", "nonbinary" = "green"),
labels = c("Men", "Women", "Nonbinary"),
breaks = c( "female",  "nonbinary", "male")) +
theme_minimal()
# Print the plot
print(splithistogramv2)
# # The code outlines a statistical analysis approach to test the hypothesis "Self-reported evaluations differ between men and women" using the 'data_processed' dataset. Two different tests are considered based on gender categorization:
#
# 1. Two-sample T-test: The data is filtered to include only "male" and "female" categories, and a two-sample t-test is conducted to compare these two groups. The 't.test' function is used, and the result is reported using the 'report' package, which provides a detailed and interpretative output of the test results.
#
# 2. ANOVA: The data is filtered to include "male", "female", and "nonbinary" categories. An ANOVA test is then run to assess differences across these gender categories. This is suitable for a broader analysis that includes all categories. The result of the ANOVA is also reported using the 'report' package for detailed insights.
#
# These statistical tests are chosen based on the nature of the hypothesis and the distribution of the gender categories in the dataset.
#
library(dplyr)
library(report)
# Filter data for male and female
data_male_female <- data_processed %>%
filter(gender %in% c("male", "female")) %>%
na.omit()
# Run the t-test
t_test_result <- t.test(mean_evaluation ~ gender, data = data_male_female, var.equal = FALSE)
# Generate the report
t_test_report <- report::report(t_test_result)
# Print the report
print(t_test_report)
# Filter data to include nonbinary
data_all_genders <- data_processed %>%
filter(gender %in% c("male", "female", "nonbinary")) %>%
na.omit()
# Run ANOVA
anova_result <- aov(mean_evaluation ~ gender, data = data_all_genders)
# Generate the report
anova_report <- report::report(anova_result)
# Print the report
print(anova_report)
# The code uses the 'patchwork' library in R to combine three different plots ('splithistogramv1', 'splitviolinv1', 'raincloudplotv1') into a single composite plot, 'combined_plot'. These plots are arranged vertically (/ operator in 'patchwork' stacks the plots). The 'print' function is then used to display the combined plot. This approach allows for a comparative visualization of the same data across different plot types, providing a comprehensive view of the data's distribution and characteristics.
library(patchwork)
# Combine the plots
combined_plot <- splithistogramv1 / splitviolinv1 / raincloudplotv1
# Print the combined plot
print(combined_plot)
# The code saves the 'combined_plot' to disk in two formats using the 'ggsave' function. The first command saves it as a PNG image file named "combined_plot.png" with a resolution of 300 DPI, suitable for high-quality print and screen displays. The second command saves the same plot as a PDF file named "combined_plot.pdf", which is ideal for publications or presentations where vector graphics are preferred for their scalability and quality.
# Save as PNG with 300 DPI
ggsave("combined_plot.png", plot = combined_plot, dpi = 300)
# Save as PDF
ggsave("combined_plot.pdf", plot = combined_plot)
# The 'sessionInfo()' command in R is used to display detailed information about the current R session. This includes the version of R, the operating system, and a list of loaded packages along with their versions. It's a useful command for documenting the computational environment in which an analysis was conducted, ensuring reproducibility and transparency.
sessionInfo()
