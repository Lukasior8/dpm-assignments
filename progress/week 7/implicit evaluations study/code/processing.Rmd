---
title: "Evaluations of positive and negative stimuli using the Affective Misattribution Procedure (AMP) and self-reports"
subtitle: "Data processing"
author: "Template: Ian Hussey; content: [Student name]"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

# Dependencies

```{r}

library(tidyverse)
library(janitor) # for clean_names()
library(stringr)

```

# Get data

```{r}

# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
  janitor::clean_names()

# data_demographics_raw_messy <- read_csv("../../../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()

# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
  janitor::clean_names()

# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
  janitor::clean_names()

```

# Demographics

```{r}

dat_age_gender <- data_demographics_raw |>
  select(subject, date, time, trialcode, response) |>
  pivot_wider(names_from = trialcode,
              values_from = response) |>
  mutate(gender = tolower(gender),
         gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
         gender = case_when(gender == "female" ~ gender,
                            gender == "male" ~ gender,
                            gender == "nonbinary" ~ gender,
                            gender == "woman" ~ "female",
                            gender == "man" ~ "male",
                            TRUE ~ "other/missing/error"),
         age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it. 
                         TRUE ~ "other/missing/error")) 

```

# Exclusions / data quality

## AMP

```{r}

data_amp_performance_criteria <- data_amp_raw |> 
  filter(blockcode != "practice", 
         trialcode != "instructions") |> 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |> 
  group_by(subject) |> 
  summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))



#assignment week 7 (2)solution with the help of chatgpt:
# 1. Exploring the Number of Trials:
# Firstly, we'll filter the data for non-practice trials and then explore the number of trials for each subject.

library(dplyr)


# Filter data for non-practice trials and count the number of trials for each subject
trial_counts <- data_amp_raw %>%
   filter(blockcode != "practice", 
          trialcode != "instructions") %>%
  group_by(subject) %>%
  summarise(num_trials = n())


# Summary of trial counts
summary(trial_counts$num_trials)
# 2. Visualizing the Number of Trials:
# A histogram will allow us to visually inspect the distribution of trial counts.
# 

library(ggplot2)

plot<- ggplot(trial_counts, aes(x=num_trials)) +
  geom_histogram(binwidth=1) +
  theme_minimal() +
  labs(title="Distribution of AMP Task Trials per Subject",
       x="Number of Trials",
       y="Number of Subjects")

print(plot)


# 3. Identifying the Common Trial Count:
# By finding the mode, we can ascertain the most frequent trial count.
# 

common_trial_count <- as.numeric(names(which.max(table(trial_counts$num_trials))))
common_trial_count


# 4. Incorporating the Exclusion Criterion:
# Now, we'll add the criterion to the existing data processing code to exclude subjects who do not have the correct number of trials.
# 

data_amp_performance_criteria <- data_amp_raw %>% 
   filter(blockcode != "practice", 
          trialcode != "instructions") %>% 
  mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) %>% 
  group_by(subject) %>% 
  mutate(num_trials = n()) %>% 
  summarize(proportion_fast_trials_amp = mean(latency_prob),
            total_trials = first(num_trials)) %>% 
  mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10 | total_trials != common_trial_count, "exclude", "include"))


# Brief Description:
# To determine the correct number of trials for the AMP task, I started by filtering out practice trials and instructions. I then counted the number of trials for each subject. By visualizing this distribution with a histogram, I could observe the pattern of trial counts across subjects. The mode of this distribution, which represents the most common trial count, was assumed to be the correct number. This value was then incorporated into the data processing code, marking subjects with an incorrect trial count for exclusion. 
# 


```

# Self-reports

```{r}

# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
  select(subject, trialcode, response) |>
  filter(trialcode %in% c("like", "prefer", "positive")) |>
  rename(item = trialcode) |>
  filter(response != "Ctrl+'B'") |>
  mutate(response = as.numeric(response))

# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
  group_by(subject) |>
  summarize(mean_evaluation = mean(response, na.rm = TRUE))

# combined
data_selfreport_scored <- 
  full_join(data_selfreport_trial_level |>
              pivot_wider(names_from = "item",
                          values_from = "response"),
            data_selfreport_mean_score,
            by = "subject")

```

# Affect Misattribution Procedure

TODO extract evaluations on the AMP test blocks and convert to an overall bias score

```{r}


```

# Combine

```{r}

# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
  full_join(data_selfreport_scored, by = "subject") |> 
  full_join(data_amp_performance_criteria, by = "subject")

# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained. 
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```

# Define master exclusions

```{r}

# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
                                         tolower(gender) == "test" ~ "exclude",
                                         is.na(mean_evaluation) ~ "exclude",
                                         # in this case we will exclude participants with missing demographics data or outcomes measures data. 
                                         # Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random. 
                                         # How to treat missing data is a  whole area of work in itself, which we wont cover here.
                                         is.na(age) ~ "exclude", 
                                         is.na(gender) ~ "exclude",
                                         exclude_amp_performance == "exclude" ~ "exclude",
                                         exclude_duplicate_data == "exclude" ~ "exclude",
                                          # Adding exclusions for missing self-report items
                                         is.na(like) ~ "exclude",
                                         is.na(positive) ~ "exclude",
                                         is.na(prefer) ~ "exclude",
                                         
                                         TRUE ~ "include"))



#assignment Weeek 7 

# 1. see above:# Adding exclusions for missing self-report items
#                                          is.na(like) ~ "exclude",
#                                          is.na(positive) ~ "exclude",
#                                          is.na(prefer) ~ "exclude",
#                                          
# 
# 2. because we already deleted duuplicate subjects. Each subject only has a trial
# count of n =1 which is in my opinine the "correct" number of trials? i dont know
# if i misunderstand the question....or is the task to choose a method for choosing a proportion of the people who have "too fast responses"??---- ahh no we have togo to aMP??








```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Session info

```{r}

sessionInfo()

```


